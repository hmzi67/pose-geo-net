# CNN-Based Head Pose Estimation Methodology
## Complete Pipeline from Input to Inference

---

## ğŸ“Š **Architecture Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    END-TO-END CNN HEAD POSE ESTIMATION                       â”‚
â”‚                     (ResNet18 + Dual-Branch Architecture)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ **Complete Methodology Flow**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              PHASE 1: DATA INPUT                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Data Sources:                                                           â”‚
â”‚  â€¢ BIWI Head Pose Database: RGB images (640Ã—480) + pose.txt files           â”‚
â”‚  â€¢ 300W-LP Dataset: Large-scale face images with annotations                â”‚
â”‚  â€¢ AFLW2000 Dataset: 2000 faces for evaluation                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PHASE 2: DATA PREPROCESSING                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Collection (data_preprocessing_cnn.py):                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  1. Image Path Collection:                                             â”‚ â”‚
â”‚  â”‚     â€¢ Scan all subjects/directories                                    â”‚ â”‚
â”‚  â”‚     â€¢ Find *_rgb.png files                                             â”‚ â”‚
â”‚  â”‚     â€¢ Verify corresponding *_pose.txt exists                           â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  2. Label Extraction:                                                  â”‚ â”‚
â”‚  â”‚     â€¢ Read pose.txt â†’ Rotation matrix R (3Ã—3)                          â”‚ â”‚
â”‚  â”‚     â€¢ Convert R â†’ Euler angles (yaw, pitch, roll) in degrees          â”‚ â”‚
â”‚  â”‚     â€¢ Formula: ypr = rotation_matrix_to_euler(R)                       â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  3. Quality Check:                                                     â”‚ â”‚
â”‚  â”‚     â€¢ Verify image loads successfully (cv2.imread)                     â”‚ â”‚
â”‚  â”‚     â€¢ Skip corrupted/missing images                                    â”‚ â”‚
â”‚  â”‚     â€¢ Apply max_frames_per_subject limit if configured                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                               â”‚
â”‚  Output: biwi_cnn_data.npz (image_paths array + labels array)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Splitting:                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  1. Label Normalization:                                               â”‚ â”‚
â”‚  â”‚     y_mean = mean(all_labels)                                          â”‚ â”‚
â”‚  â”‚     y_std = std(all_labels) + 1e-8                                     â”‚ â”‚
â”‚  â”‚     y_normalized = (y - y_mean) / y_std                                â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  2. Train/Val/Test Split:                                              â”‚ â”‚
â”‚  â”‚     â€¢ Test: 20% (held-out)                                             â”‚ â”‚
â”‚  â”‚     â€¢ Validation: 20% of remaining                                     â”‚ â”‚
â”‚  â”‚     â€¢ Train: 60% of total                                              â”‚ â”‚
â”‚  â”‚     â€¢ Stratified random split with fixed seed                          â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  3. Save Splits:                                                       â”‚ â”‚
â”‚  â”‚     â€¢ biwi_cnn_train.npz (paths, labels, y_mean, y_std)               â”‚ â”‚
â”‚  â”‚     â€¢ biwi_cnn_val.npz (paths, labels, y_mean, y_std)                 â”‚ â”‚
â”‚  â”‚     â€¢ biwi_cnn_test.npz (paths, labels, y_mean, y_std)                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PHASE 3: DATASET CREATION                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BIWIImageDataset (PyTorch Dataset):                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  __getitem__(idx):                                                     â”‚ â”‚
â”‚  â”‚    1. Load Image:                                                      â”‚ â”‚
â”‚  â”‚       img = cv2.imread(image_paths[idx], IMREAD_COLOR)                 â”‚ â”‚
â”‚  â”‚       img = cv2.cvtColor(img, COLOR_BGR2RGB)                           â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚    2. Data Augmentation (Training only):                               â”‚ â”‚
â”‚  â”‚       â€¢ Resize to 224Ã—224 (ResNet input size)                          â”‚ â”‚
â”‚  â”‚       â€¢ ColorJitter (brightness, contrast, saturation, hue)            â”‚ â”‚
â”‚  â”‚       â€¢ RandomHorizontalFlip (p=0.5)                                   â”‚ â”‚
â”‚  â”‚       â€¢ ToTensor (scale to [0,1])                                      â”‚ â”‚
â”‚  â”‚       â€¢ Normalize with ImageNet stats:                                 â”‚ â”‚
â”‚  â”‚         mean=[0.485, 0.456, 0.406]                                     â”‚ â”‚
â”‚  â”‚         std=[0.229, 0.224, 0.225]                                      â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚    3. Return:                                                          â”‚ â”‚
â”‚  â”‚       image_tensor [3, 224, 224], label_tensor [3]                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DataLoader Configuration (Optimized for RTX 3090):                          â”‚
â”‚  â€¢ batch_size: 64                                                            â”‚
â”‚  â€¢ num_workers: 8 (train), 4 (val/test)                                     â”‚
â”‚  â€¢ pin_memory: True                                                          â”‚
â”‚  â€¢ prefetch_factor: 4 (train), 2 (val/test)                                 â”‚
â”‚  â€¢ persistent_workers: True                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PHASE 4: MODEL ARCHITECTURE                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CNNBasedHeadPoseModel Architecture                       â”‚
â”‚                                                                               â”‚
â”‚  Input: RGB Image [batch, 3, 224, 224]                                      â”‚
â”‚     â”‚                                                                         â”‚
â”‚     â–¼                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                   COMPONENT 1: CNN FEATURE EXTRACTOR                 â”‚    â”‚
â”‚  â”‚                      (ResNet18FeatureExtractor)                      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â”‚                                                                         â”‚
â”‚     â”œâ”€â”€â–º ResNet18 Backbone (Pretrained on ImageNet):                        â”‚
â”‚     â”‚    â€¢ Conv1: 7Ã—7, stride=2                                              â”‚
â”‚     â”‚    â€¢ MaxPool: 3Ã—3, stride=2                                            â”‚
â”‚     â”‚    â€¢ Layer1: 2 Ã— BasicBlock (64 channels)                             â”‚
â”‚     â”‚    â€¢ Layer2: 2 Ã— BasicBlock (128 channels)                            â”‚
â”‚     â”‚    â€¢ Layer3: 2 Ã— BasicBlock (256 channels)                            â”‚
â”‚     â”‚    â€¢ Layer4: 2 Ã— BasicBlock (512 channels)                            â”‚
â”‚     â”‚    â€¢ AdaptiveAvgPool2d(1Ã—1)                                            â”‚
â”‚     â”‚    Output: [batch, 512]                                                â”‚
â”‚     â”‚                                                                         â”‚
â”‚     â”œâ”€â”€â–º Shared Feature Processing:                                          â”‚
â”‚     â”‚    â€¢ Linear(512 â†’ 1024)                                                â”‚
â”‚     â”‚    â€¢ ReLU                                                              â”‚
â”‚     â”‚    â€¢ BatchNorm1d(1024)                                                 â”‚
â”‚     â”‚    â€¢ Dropout(0.3)                                                      â”‚
â”‚     â”‚    Output: [batch, 1024]                                               â”‚
â”‚     â”‚                                                                         â”‚
â”‚     â”œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚     â”‚      â”‚                                                       â”‚         â”‚
â”‚     â–¼      â–¼                                                       â–¼         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Face Head         â”‚                            â”‚   Pose Head         â”‚ â”‚
â”‚  â”‚   (Face Features)   â”‚                            â”‚   (Pose Features)   â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ Linear(1024 â†’ 768)  â”‚                            â”‚ Linear(1024 â†’ 256)  â”‚ â”‚
â”‚  â”‚ ReLU                â”‚                            â”‚ ReLU                â”‚ â”‚
â”‚  â”‚ BatchNorm1d(768)    â”‚                            â”‚ BatchNorm1d(256)    â”‚ â”‚
â”‚  â”‚ Dropout(0.2)        â”‚                            â”‚ Dropout(0.2)        â”‚ â”‚
â”‚  â”‚ Linear(768 â†’ 1404)  â”‚                            â”‚ Linear(256 â†’ 99)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚     â”‚                                                       â”‚                â”‚
â”‚     â”‚ [batch, 1404]                                        â”‚ [batch, 99]    â”‚
â”‚     â”‚ (Mimics 468 face landmarks Ã— 3)                     â”‚ (Mimics 33     â”‚
â”‚     â”‚                                                       â”‚  pose Ã— 3)     â”‚
â”‚     â”‚                                                       â”‚                â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                         â–¼                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              COMPONENT 2: DUAL-BRANCH ENCODERS                       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â”‚                                                                         â”‚
â”‚     â”œâ”€â”€â–º Face Encoder (FaceEncoder):                                         â”‚
â”‚     â”‚    â€¢ Linear(1404 â†’ 512) + ReLU + BatchNorm + Dropout(0.1)             â”‚
â”‚     â”‚    â€¢ Linear(512 â†’ 256) + ReLU + BatchNorm + Dropout(0.1)              â”‚
â”‚     â”‚    Output: [batch, 256] (face_encoded)                                â”‚
â”‚     â”‚                                                                         â”‚
â”‚     â””â”€â”€â–º Pose Encoder (PoseEncoder):                                         â”‚
â”‚          â€¢ Linear(99 â†’ 128) + ReLU + BatchNorm + Dropout(0.1)               â”‚
â”‚          â€¢ Linear(128 â†’ 64) + ReLU + BatchNorm + Dropout(0.1)               â”‚
â”‚          Output: [batch, 64] (pose_encoded)                                 â”‚
â”‚                                                                               â”‚
â”‚                         â”‚                                                    â”‚
â”‚                         â–¼                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              COMPONENT 3: FEATURE FUSION                             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â”‚                                                                         â”‚
â”‚     â”œâ”€â”€â–º Concatenation:                                                      â”‚
â”‚     â”‚    fused_input = concat([face_encoded, pose_encoded], dim=1)          â”‚
â”‚     â”‚    Shape: [batch, 256 + 64] = [batch, 320]                            â”‚
â”‚     â”‚                                                                         â”‚
â”‚     â””â”€â”€â–º Fusion Layer:                                                       â”‚
â”‚          â€¢ Linear(320 â†’ 256) + ReLU + BatchNorm + Dropout(0.1)              â”‚
â”‚          Output: [batch, 256] (fused_features)                              â”‚
â”‚                                                                               â”‚
â”‚                         â”‚                                                    â”‚
â”‚                         â–¼                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚            COMPONENT 4: REGRESSION HEAD                              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚     â”‚                                                                         â”‚
â”‚     â””â”€â”€â–º Angle Prediction:                                                   â”‚
â”‚          â€¢ Linear(256 â†’ 128) + ReLU + Dropout(0.05)                         â”‚
â”‚          â€¢ Linear(128 â†’ 3)                                                   â”‚
â”‚          Output: [batch, 3] (yaw, pitch, roll) - normalized                 â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          PHASE 5: TRAINING PROCESS                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Training Configuration:                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Optimizer: AdamW                                                      â”‚ â”‚
â”‚  â”‚    â€¢ learning_rate: 0.001 (default)                                   â”‚ â”‚
â”‚  â”‚    â€¢ weight_decay: 0.01 (L2 regularization)                           â”‚ â”‚
â”‚  â”‚    â€¢ betas: (0.9, 0.999)                                              â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  Loss Function: MSE (Mean Squared Error)                               â”‚ â”‚
â”‚  â”‚    loss = MSE(predictions, targets)                                    â”‚ â”‚
â”‚  â”‚         = mean((predictions - targets)Â²)                               â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  Mixed Precision Training (FP16):                                      â”‚ â”‚
â”‚  â”‚    â€¢ GradScaler for automatic loss scaling                             â”‚ â”‚
â”‚  â”‚    â€¢ torch.amp.autocast for forward pass                               â”‚ â”‚
â”‚  â”‚    â€¢ Reduces memory usage by ~50%                                      â”‚ â”‚
â”‚  â”‚    â€¢ Speeds up computation on RTX 3090                                 â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  Early Stopping:                                                       â”‚ â”‚
â”‚  â”‚    â€¢ Monitor validation MAE                                            â”‚ â”‚
â”‚  â”‚    â€¢ Patience: 15 epochs                                               â”‚ â”‚
â”‚  â”‚    â€¢ Save best model state                                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Training Loop (per epoch):                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  FOR EACH BATCH:                                                       â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚    1. Load Batch:                                                      â”‚ â”‚
â”‚  â”‚       images, targets = next(train_loader)                             â”‚ â”‚
â”‚  â”‚       images â†’ GPU (non_blocking=True)                                 â”‚ â”‚
â”‚  â”‚       targets â†’ GPU (non_blocking=True)                                â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚    2. Forward Pass (with autocast):                                    â”‚ â”‚
â”‚  â”‚       with torch.amp.autocast('cuda'):                                 â”‚ â”‚
â”‚  â”‚         predictions = model(images)                                    â”‚ â”‚
â”‚  â”‚         loss = criterion(predictions, targets)                         â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚    3. Backward Pass (with gradient scaling):                           â”‚ â”‚
â”‚  â”‚       optimizer.zero_grad(set_to_none=True)                            â”‚ â”‚
â”‚  â”‚       scaler.scale(loss).backward()                                    â”‚ â”‚
â”‚  â”‚       scaler.step(optimizer)                                           â”‚ â”‚
â”‚  â”‚       scaler.update()                                                  â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚    4. Accumulate Metrics:                                              â”‚ â”‚
â”‚  â”‚       total_loss += loss.item()                                        â”‚ â”‚
â”‚  â”‚       all_preds.append(predictions.detach())                           â”‚ â”‚
â”‚  â”‚       all_targets.append(targets.detach())                             â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  END FOR                                                               â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  5. Epoch Metrics:                                                     â”‚ â”‚
â”‚  â”‚     â€¢ Denormalize predictions and targets:                             â”‚ â”‚
â”‚  â”‚       pred_deg = pred_norm Ã— y_std + y_mean                            â”‚ â”‚
â”‚  â”‚       target_deg = target_norm Ã— y_std + y_mean                        â”‚ â”‚
â”‚  â”‚     â€¢ Calculate MAE per angle:                                         â”‚ â”‚
â”‚  â”‚       mae_yaw = mean(|pred_yaw - target_yaw|)                          â”‚ â”‚
â”‚  â”‚       mae_pitch = mean(|pred_pitch - target_pitch|)                    â”‚ â”‚
â”‚  â”‚       mae_roll = mean(|pred_roll - target_roll|)                       â”‚ â”‚
â”‚  â”‚       mae_overall = mean([mae_yaw, mae_pitch, mae_roll])               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Validation Loop (per epoch):                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  with torch.no_grad():                                                 â”‚ â”‚
â”‚  â”‚    FOR EACH BATCH:                                                     â”‚ â”‚
â”‚  â”‚      1. Load batch â†’ GPU                                               â”‚ â”‚
â”‚  â”‚      2. Forward pass (with autocast)                                   â”‚ â”‚
â”‚  â”‚      3. Calculate loss and accumulate                                  â”‚ â”‚
â”‚  â”‚    END FOR                                                             â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  4. Calculate validation metrics (same as training)                    â”‚ â”‚
â”‚  â”‚  5. Check early stopping:                                              â”‚ â”‚
â”‚  â”‚     IF val_mae_overall < best_val_mae:                                 â”‚ â”‚
â”‚  â”‚       best_val_mae = val_mae_overall                                   â”‚ â”‚
â”‚  â”‚       Save model checkpoint:                                           â”‚ â”‚
â”‚  â”‚         â€¢ model_state_dict                                             â”‚ â”‚
â”‚  â”‚         â€¢ optimizer_state_dict                                         â”‚ â”‚
â”‚  â”‚         â€¢ y_mean, y_std                                                â”‚ â”‚
â”‚  â”‚         â€¢ config                                                       â”‚ â”‚
â”‚  â”‚         â€¢ epoch number                                                 â”‚ â”‚
â”‚  â”‚       epochs_no_improve = 0                                            â”‚ â”‚
â”‚  â”‚     ELSE:                                                              â”‚ â”‚
â”‚  â”‚       epochs_no_improve += 1                                           â”‚ â”‚
â”‚  â”‚       IF epochs_no_improve >= patience:                                â”‚ â”‚
â”‚  â”‚         STOP TRAINING (early stopping triggered)                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Test Evaluation (after each epoch):                                         â”‚
â”‚  â€¢ Same as validation loop but on test set                                  â”‚
â”‚  â€¢ Provides unbiased performance estimate                                   â”‚
â”‚  â€¢ Metrics logged to history                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          PHASE 6: MODEL SAVING                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Checkpoint Saved to: models/saved/cervical_headpose_cnn_[dataset]_best.pth â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Checkpoint Contents:                                                  â”‚ â”‚
â”‚  â”‚  {                                                                     â”‚ â”‚
â”‚  â”‚    'epoch': best_epoch,                                                â”‚ â”‚
â”‚  â”‚    'model_state': model.state_dict(),                                 â”‚ â”‚
â”‚  â”‚    'optimizer_state': optimizer.state_dict(),                          â”‚ â”‚
â”‚  â”‚    'y_mean': normalization_mean,                                       â”‚ â”‚
â”‚  â”‚    'y_std': normalization_std,                                         â”‚ â”‚
â”‚  â”‚    'config': training_config                                           â”‚ â”‚
â”‚  â”‚  }                                                                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          PHASE 7: INFERENCE                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Inference Pipeline (test_cnn_model.py):                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  1. Model Loading:                                                     â”‚ â”‚
â”‚  â”‚     â€¢ Load checkpoint from file                                        â”‚ â”‚
â”‚  â”‚     â€¢ Create model architecture                                        â”‚ â”‚
â”‚  â”‚     â€¢ Load state_dict into model                                       â”‚ â”‚
â”‚  â”‚     â€¢ Extract y_mean, y_std for denormalization                        â”‚ â”‚
â”‚  â”‚     â€¢ Set model.eval() mode                                            â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  2. Input Processing:                                                  â”‚ â”‚
â”‚  â”‚     FOR EACH TEST IMAGE:                                               â”‚ â”‚
â”‚  â”‚       a. Load image: cv2.imread()                                      â”‚ â”‚
â”‚  â”‚       b. Convert BGR â†’ RGB                                             â”‚ â”‚
â”‚  â”‚       c. Resize to 224Ã—224                                             â”‚ â”‚
â”‚  â”‚       d. Normalize with ImageNet stats                                 â”‚ â”‚
â”‚  â”‚       e. Convert to tensor [1, 3, 224, 224]                           â”‚ â”‚
â”‚  â”‚       f. Move to GPU                                                   â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  3. Forward Pass:                                                      â”‚ â”‚
â”‚  â”‚     with torch.no_grad():                                              â”‚ â”‚
â”‚  â”‚       with torch.amp.autocast('cuda'):                                 â”‚ â”‚
â”‚  â”‚         predictions = model(image_tensor)                              â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  4. Output Processing:                                                 â”‚ â”‚
â”‚  â”‚     â€¢ Denormalize predictions:                                         â”‚ â”‚
â”‚  â”‚       angles_deg = predictions Ã— y_std + y_mean                        â”‚ â”‚
â”‚  â”‚     â€¢ Convert to CPU and numpy                                         â”‚ â”‚
â”‚  â”‚     â€¢ Extract: [yaw, pitch, roll] in degrees                           â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  5. Evaluation Metrics:                                                â”‚ â”‚
â”‚  â”‚     â€¢ Calculate MAE per angle (degrees)                                â”‚ â”‚
â”‚  â”‚     â€¢ Calculate overall MAE                                            â”‚ â”‚
â”‚  â”‚     â€¢ Calculate MSE                                                    â”‚ â”‚
â”‚  â”‚     â€¢ Generate error distributions                                     â”‚ â”‚
â”‚  â”‚     â€¢ Create confusion/scatter plots                                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        PHASE 8: VISUALIZATION                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Visualization Components (visualize_cnn_predictions.py):                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  1. Box Plots:                                                         â”‚ â”‚
â”‚  â”‚     â€¢ Error distribution per angle (yaw, pitch, roll)                  â”‚ â”‚
â”‚  â”‚     â€¢ Shows median, quartiles, outliers                                â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  2. Scatter Plots:                                                     â”‚ â”‚
â”‚  â”‚     â€¢ Predicted vs Actual for each angle                               â”‚ â”‚
â”‚  â”‚     â€¢ Perfect prediction line (y=x)                                    â”‚ â”‚
â”‚  â”‚     â€¢ RÂ² correlation coefficient                                       â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  3. Error Histograms:                                                  â”‚ â”‚
â”‚  â”‚     â€¢ Distribution of absolute errors                                  â”‚ â”‚
â”‚  â”‚     â€¢ Separate histogram per angle                                     â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  4. Cumulative Error Curves:                                           â”‚ â”‚
â”‚  â”‚     â€¢ Percentage of predictions within error threshold                 â”‚ â”‚
â”‚  â”‚     â€¢ Similar to ROC curve for regression                              â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  5. Sample Visualizations:                                             â”‚ â”‚
â”‚  â”‚     â€¢ Overlay predicted angles on test images                          â”‚ â”‚
â”‚  â”‚     â€¢ Show best and worst predictions                                  â”‚ â”‚
â”‚  â”‚     â€¢ Color-coded error severity                                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

---

## ğŸ¯ **Key Innovations & Features**

### 1. **End-to-End Learnable Architecture**
```
Traditional: Image â†’ MediaPipe (fixed) â†’ MLP
Our Approach: Image â†’ CNN (learnable) â†’ Dual-Branch â†’ MLP
```
- No dependency on external landmark detection
- Learned features optimized for head pose estimation
- Better generalization to diverse datasets

### 2. **Dual-Branch Design**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CNN Feature â”‚
â”‚  Extractor   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â–º Face Branch (1404 dims) â”€â”€â”
       â”‚                                 â”œâ”€â”€â–º Fusion â”€â”€â–º Regression
       â””â”€â”€â”€â”€â–º Pose Branch (99 dims) â”€â”€â”€â”€â”˜
```
- Separate processing for facial and postural information
- Mimics MediaPipe's face + pose landmark structure
- Maintains interpretability while being fully learnable

### 3. **GPU Optimization for RTX 3090**
```
Optimization Techniques:
âœ“ Mixed Precision Training (FP16)       â†’ 50% memory reduction
âœ“ Persistent Workers (8 workers)        â†’ Efficient data loading
âœ“ Pin Memory + Non-blocking Transfer    â†’ Faster GPU-CPU comm
âœ“ Prefetch Factor (4x)                  â†’ Overlapped I/O
âœ“ Gradient Accumulation Ready           â†’ Large batch support
```

### 4. **Robust Training Pipeline**
```
Features:
â€¢ Automatic Mixed Precision (AMP)
â€¢ Early Stopping with patience
â€¢ Model checkpointing (best validation)
â€¢ Comprehensive metrics logging
â€¢ Error handling and recovery
```

---

## ğŸ“ˆ **Data Flow Summary**

```
Raw Image (640Ã—480Ã—3)
    â†“
Resize & Augment â†’ (224Ã—224Ã—3)
    â†“
Normalize (ImageNet stats)
    â†“
ResNet18 Backbone â†’ [512 features]
    â†“
Shared FC â†’ [1024 features]
    â†“
Split into 2 heads
    â”œâ”€â–º Face Head â†’ [1404] â”€â”€â”€â”
    â””â”€â–º Pose Head â†’ [99]  â”€â”€â”€â”€â”¤
                              â†“
                        Concatenate
                              â†“
                    Face Encoder [256]
                    Pose Encoder [64]
                              â†“
                        Fusion [256]
                              â†“
                    Regression Head [3]
                              â†“
                    (yaw, pitch, roll)
```

---

## ğŸ”§ **Hyperparameters**

| Component | Parameter | Value |
|-----------|-----------|-------|
| **Input** | Image Size | 224Ã—224 |
| | Normalization | ImageNet stats |
| **Architecture** | Backbone | ResNet18 (pretrained) |
| | Face Features | 1404 |
| | Pose Features | 99 |
| | Fusion Dim | 256 |
| **Training** | Batch Size | 64 |
| | Learning Rate | 0.001 |
| | Optimizer | AdamW |
| | Weight Decay | 0.01 |
| | Loss Function | MSE |
| | Early Stopping | 15 epochs |
| **Augmentation** | ColorJitter | 0.2 |
| | Horizontal Flip | 0.5 |
| **Hardware** | Precision | FP16 (Mixed) |
| | Workers | 8 (train), 4 (val/test) |
| | Prefetch | 4 (train), 2 (val/test) |

---

## ğŸ“Š **Evaluation Metrics**

### Training Metrics (per epoch):
1. **Loss**: MSE on normalized angles
2. **MAE**: Mean Absolute Error per angle (degrees)
   - MAE Yaw
   - MAE Pitch
   - MAE Roll
   - MAE Overall (average)

### Test Metrics:
1. **Accuracy**: Percentage within threshold (e.g., Â±5Â°)
2. **RÂ² Score**: Correlation between predicted and actual
3. **Error Distribution**: Histogram of absolute errors
4. **Cumulative Error**: Percentage vs error threshold curve

---

## ğŸš€ **Usage Commands**

### 1. Data Preprocessing:
```bash
python src/data_preprocessing_cnn.py --config config/config.yaml
```

### 2. Training:
```bash
python train_cnn_model.py --dataset biwi --epochs 100 --batch-size 64
python train_cnn_model.py --dataset 300wlp --epochs 50
```

### 3. Testing:
```bash
python test_cnn_model.py
```

### 4. Visualization:
```bash
python visualize_cnn_predictions.py
```

---

## ğŸ“ **File Structure**

```
src/
â”œâ”€â”€ data_preprocessing_cnn.py      # Dataset creation & splitting
â”œâ”€â”€ cnn_feature_extractor.py       # ResNet18 + Dual-Branch model
â”œâ”€â”€ trainer_cnn.py                 # Training loop & evaluation
â””â”€â”€ utils.py                       # Helper functions

models/
â”œâ”€â”€ mlp_model.py                   # Dual-branch components
â””â”€â”€ saved/
    â””â”€â”€ cervical_headpose_cnn_*.pth  # Trained models

data/
â”œâ”€â”€ splits/
â”‚   â”œâ”€â”€ biwi_cnn_train.npz
â”‚   â”œâ”€â”€ biwi_cnn_val.npz
â”‚   â””â”€â”€ biwi_cnn_test.npz
â””â”€â”€ BIWI/                          # Raw images

train_cnn_model.py                 # Main training script
test_cnn_model.py                  # Inference & evaluation
visualize_cnn_predictions.py       # Visualization tools
```

---

## ğŸ“ **Research Contribution**

This methodology presents:
1. **Novel Architecture**: End-to-end CNN replacing fixed landmark extraction
2. **Dual-Branch Design**: Separate face and pose feature processing
3. **Optimized Implementation**: GPU-accelerated training for RTX 3090
4. **Comprehensive Evaluation**: Multi-metric analysis and visualization
5. **Reproducible Pipeline**: Complete data preprocessing to inference

The approach achieves competitive performance while being fully learnable and adaptable to different datasets without requiring MediaPipe or other external landmark detectors.

---

## ğŸ“– **References**

- **Backbone**: ResNet18 (He et al., 2016)
- **Datasets**: BIWI, 300W-LP, AFLW2000
- **Framework**: PyTorch 2.0+
- **Optimization**: Mixed Precision Training (NVIDIA Apex/AMP)

---

*Last Updated: January 14, 2026*
