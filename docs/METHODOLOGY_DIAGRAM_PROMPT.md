# Prompt to Generate CNN Training Methodology Diagram

## ğŸ“ Complete Prompt

```
Create a comprehensive methodology diagram in Markdown format for a CNN-based head pose estimation system. The diagram should cover the complete pipeline from raw input data to final inference and visualization.

## Required Structure:

### 1. OVERVIEW SECTION
- Title: "CNN-Based Head Pose Estimation Methodology"
- Subtitle: "Complete Pipeline from Input to Inference"
- Brief architecture overview showing end-to-end flow

### 2. PHASE-BY-PHASE BREAKDOWN

#### Phase 1: Data Input
- List all data sources (BIWI, 300W-LP, AFLW2000)
- Specify raw data formats (images + annotations)
- Show initial data structure

#### Phase 2: Data Preprocessing
- Image path collection process
- Label extraction methodology (rotation matrix to Euler angles)
- Quality checks and validation
- Data normalization (mean, std)
- Train/Val/Test splitting strategy
- Output file formats (.npz files)

#### Phase 3: Dataset Creation
- PyTorch Dataset class implementation
- Data loading mechanism (cv2.imread)
- Data augmentation pipeline:
  * Resize operations
  * ColorJitter parameters
  * Random flips
  * Normalization with ImageNet statistics
- DataLoader configuration (batch size, workers, pin_memory, prefetch)

#### Phase 4: Model Architecture
Provide DETAILED architecture breakdown:

**Component 1: CNN Feature Extractor**
- Backbone: ResNet18 (pretrained)
- Layer-by-layer breakdown:
  * Conv layers with filter sizes
  * Pooling layers
  * Feature dimensions at each stage
- Shared feature processing
- Dual-head split:
  * Face Head â†’ outputs dimensions
  * Pose Head â†’ outputs dimensions

**Component 2: Dual-Branch Encoders**
- Face Encoder architecture (inputâ†’hiddenâ†’output dims)
- Pose Encoder architecture (inputâ†’hiddenâ†’output dims)
- Activation functions and regularization

**Component 3: Feature Fusion**
- Concatenation strategy
- Fusion layer architecture
- Output dimensions

**Component 4: Regression Head**
- Hidden layer configuration
- Output layer (3 for yaw, pitch, roll)
- Final activation

#### Phase 5: Training Process
- Optimizer details (AdamW with hyperparameters)
- Loss function (MSE)
- Mixed precision training (FP16/AMP)
- Training loop structure:
  * Batch loading
  * Forward pass with autocast
  * Backward pass with gradient scaling
  * Metric accumulation
- Validation loop
- Early stopping mechanism
- Checkpoint saving strategy

#### Phase 6: Model Saving
- Checkpoint contents (model_state, optimizer_state, normalization stats)
- File naming convention
- Save location

#### Phase 7: Inference
- Model loading process
- Input preprocessing for inference
- Forward pass (with torch.no_grad)
- Output denormalization
- Angle extraction (yaw, pitch, roll)
- Evaluation metrics calculation

#### Phase 8: Visualization
- Box plots (error distribution)
- Scatter plots (predicted vs actual)
- Error histograms
- Cumulative error curves
- Sample visualizations on images

### 3. DATA FLOW DIAGRAM
Create an ASCII art diagram showing:
- Input dimensions at each stage
- Transformation operations
- Output shapes
- Flow arrows connecting components
Example format:
```
Raw Image (HÃ—WÃ—C)
    â†“
Process
    â†“
Output (dims)
```

### 4. KEY INNOVATIONS SECTION
- Compare with traditional approaches
- Highlight novel contributions:
  * End-to-end learnable vs fixed features
  * Dual-branch design rationale
  * GPU optimization strategies
  * Robust training pipeline features

### 5. TECHNICAL SPECIFICATIONS

**Table 1: Hyperparameters**
Create a table with:
- Component (Input, Architecture, Training, Augmentation, Hardware)
- Parameter name
- Value
- Brief description (optional)

**Table 2: Evaluation Metrics**
- Training metrics (MSE, MAE per angle)
- Test metrics (Accuracy, RÂ², Error distribution)
- Visualization metrics

### 6. USAGE SECTION
Provide command-line examples for:
- Data preprocessing
- Training (with different datasets/parameters)
- Testing
- Visualization

### 7. FILE STRUCTURE
Show directory tree with:
- Source code files with brief descriptions
- Model save directories
- Data directories
- Training/testing scripts

### 8. RESEARCH CONTRIBUTION
Summarize the novelty:
- What problem does this solve?
- Why is this approach better?
- What are the key innovations?
- Performance characteristics

### 9. REFERENCES
- Backbone architecture papers
- Dataset sources
- Framework versions
- Optimization techniques

## Formatting Requirements:

1. **Use ASCII Art Diagrams**:
   - Box drawings with â”Œâ”€â”â”‚â””â”˜
   - Arrows with â†â†’â†‘â†“
   - Tree structures with â”œâ”€â”¤

2. **Use Emoji Icons**:
   - ğŸ“Š for data/statistics
   - ğŸ”„ for processes
   - ğŸ¯ for goals/targets
   - ğŸš€ for performance
   - ğŸ“ for files
   - ğŸ“ for research
   - âœ“ for checkmarks/success

3. **Code Blocks**:
   - Use ```python for code snippets
   - Use ```bash for commands
   - Use ``` for generic text blocks

4. **Headers**:
   - # for main title
   - ## for phases
   - ### for components
   - #### for sub-components

5. **Lists**:
   - Use â€¢ for bullet points in diagrams
   - Use numbered lists for sequential steps
   - Use indentation for hierarchy

6. **Tables**:
   - Use Markdown table format
   - Include headers
   - Align appropriately

7. **Visual Clarity**:
   - Use horizontal rules (---) between major sections
   - Add blank lines for readability
   - Indent nested components
   - Use consistent spacing

## Tone and Style:

- **Technical but accessible**: Explain complex concepts clearly
- **Comprehensive**: Cover every step from input to output
- **Visual**: Heavy use of diagrams and structured layouts
- **Practical**: Include actual commands and file paths
- **Professional**: Suitable for research papers or documentation

## Key Information to Include:

**Architecture Details**:
- Exact layer dimensions (e.g., "Linear(512 â†’ 1024)")
- Activation functions at each layer
- Dropout rates
- Batch normalization placement

**Data Pipeline**:
- Image loading method (cv2, PIL, etc.)
- Exact augmentation parameters
- Normalization statistics (mean=[...], std=[...])
- Batch size and worker configuration

**Training Details**:
- Learning rate and schedule
- Loss function formula
- Gradient scaling approach
- Early stopping criteria
- Checkpoint frequency

**Performance Optimizations**:
- GPU-specific optimizations
- Memory management techniques
- Data loading optimizations
- Mixed precision benefits

**Reproducibility**:
- Random seeds
- Split ratios
- Configuration file locations
- Dependency versions

## Output Format:

Generate a single Markdown file with:
- Clear section breaks
- Logical flow from input â†’ processing â†’ output
- Both high-level overview and detailed specifications
- Visual diagrams throughout
- Practical usage examples
- Complete technical documentation

The final document should serve as:
1. Technical documentation for developers
2. Methodology section for research papers
3. Training guide for new users
4. Reference for troubleshooting
5. Template for similar projects
```

---

## ğŸ¯ **How to Use This Prompt**

### For AI/LLM:
```
Copy the entire prompt above and provide it to an AI assistant along with:
- Your actual code files (preprocessing, model, trainer)
- Configuration files (config.yaml)
- Dataset information
- Training logs or results

The AI will generate a comprehensive methodology diagram following this structure.
```

### For Manual Creation:
```
Use this as a checklist and template:
1. Follow each section in order
2. Fill in your specific details
3. Create diagrams matching the ASCII art style
4. Include all technical specifications
5. Add your actual file paths and commands
6. Customize based on your specific implementation
```

### For Documentation:
```
This prompt can serve as:
- A documentation standard for ML projects
- A methodology template for research papers
- A structure for technical presentations
- A guide for code review and validation
```

---

## ğŸ“‹ **Checklist for Complete Diagram**

Use this to verify your methodology diagram is complete:

- [ ] **Title and Overview** - Clear project description
- [ ] **8 Phases Documented** - All phases from input to visualization
- [ ] **Architecture Diagrams** - Visual representation of model
- [ ] **Data Flow** - Shows transformations at each step
- [ ] **Code References** - Links to actual implementation files
- [ ] **Hyperparameters Table** - Complete configuration details
- [ ] **Training Process** - Step-by-step training loop
- [ ] **Evaluation Metrics** - All metrics explained
- [ ] **Usage Commands** - Actual runnable commands
- [ ] **File Structure** - Directory tree with descriptions
- [ ] **Innovations Highlighted** - Novel contributions explained
- [ ] **GPU Optimizations** - Performance enhancements documented
- [ ] **Reproducibility Info** - Seeds, splits, versions
- [ ] **Visual Clarity** - ASCII diagrams and formatting
- [ ] **References** - Papers, datasets, frameworks cited

---

## ğŸ”§ **Customization Options**

### For Different Architectures:
```
Replace ResNet18 with your backbone:
- VGG16/19
- EfficientNet
- Vision Transformer (ViT)
- Custom CNN

Adjust:
- Feature dimensions
- Layer descriptions
- Computational complexity
```

### For Different Tasks:
```
Adapt for other regression/classification tasks:
- Facial landmark detection
- Age estimation
- Emotion recognition
- Object pose estimation

Modify:
- Output dimensions
- Loss functions
- Evaluation metrics
```

### For Different Frameworks:
```
Convert to other frameworks:
- TensorFlow/Keras
- JAX
- MXNet

Update:
- Code syntax
- Optimization APIs
- Model saving formats
```

---

## ğŸ’¡ **Tips for Best Results**

1. **Be Specific**: Include exact dimensions, not "hidden_size"
2. **Show Flow**: Use arrows and boxes to show data movement
3. **Include Context**: Explain WHY choices were made, not just WHAT
4. **Add Examples**: Show sample inputs/outputs with actual values
5. **Reference Code**: Link diagram elements to actual code files
6. **Visualize Everything**: Convert text descriptions to diagrams
7. **Layer Details**: Show each transformation with inputâ†’output shapes
8. **Optimization Notes**: Explain performance choices (why FP16, why 8 workers)
9. **Error Handling**: Document edge cases and failure modes
10. **Validation**: Include how to verify each step works correctly

---

## ğŸ“š **Example Prompt Usage**

### Scenario 1: Documenting Existing Code
```
I have a head pose estimation system with these files:
- src/cnn_feature_extractor.py (ResNet18 + dual heads)
- src/trainer_cnn.py (training loop)
- train_cnn_model.py (main script)

Generate a methodology diagram following the structure in 
METHODOLOGY_DIAGRAM_PROMPT.md that documents this complete pipeline.
```

### Scenario 2: Planning New Architecture
```
I want to build a facial expression recognition system using:
- EfficientNet-B0 backbone
- Attention mechanism
- Multi-task learning (expression + valence/arousal)

Use METHODOLOGY_DIAGRAM_PROMPT.md as a template to create a 
methodology diagram for this architecture before implementation.
```

### Scenario 3: Research Paper
```
I need a methodology section for my paper on cervical head pose 
estimation. The system uses CNN-based approach with dual-branch 
architecture. Generate a methodology diagram using 
METHODOLOGY_DIAGRAM_PROMPT.md that is suitable for academic publication.
```

---

## ğŸ¨ **Visual Style Guide**

### ASCII Box Styles:
```
Simple Box:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Content   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Nested Box:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Outer                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Inner                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Flow Diagram:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Process â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Output  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Split Flow:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Input  â”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
             â”‚
      â”â”â”â”â”â”â”â”»â”â”â”â”â”â”â”“
      â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Branch Aâ”‚    â”‚ Branch Bâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
      â”—â”â”â”â”â”â”â”³â”â”â”â”â”â”â”›
             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Merged  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dimension Notation:
```
Tensor Shapes:
[batch, channels, height, width]     â†’ [64, 3, 224, 224]
[batch, features]                     â†’ [64, 512]
[batch, sequence, features]           â†’ [64, 100, 256]

Layer Notation:
Linear(input_dim â†’ output_dim)        â†’ Linear(512 â†’ 256)
Conv2d(in_ch, out_ch, kernel)         â†’ Conv2d(3, 64, 7Ã—7)
```

### Color Coding (using emojis):
```
âœ… Success / Completed
âŒ Error / Failed
âš ï¸  Warning / Caution
ğŸ”µ Information
ğŸŸ¢ Training phase
ğŸŸ¡ Validation phase
ğŸ”´ Testing phase
```

---

## ğŸ“– **Additional Resources**

### Related Templates:
- `CNN_METHODOLOGY_DIAGRAM.md` - Example output
- `config/config.yaml` - Configuration structure
- `TRAINING_STATUS.md` - Training documentation template
- `GPU_OPTIMIZATION_GUIDE.md` - Performance optimization guide

### Best Practices:
1. Update diagram when architecture changes
2. Version control methodology documents
3. Include in project README
4. Use for onboarding new team members
5. Reference in research publications

---

*This prompt template ensures comprehensive, consistent, and professional methodology documentation for machine learning projects.*

**Version**: 1.0  
**Last Updated**: January 14, 2026  
**Compatible With**: PyTorch 2.0+, CNN-based architectures, Regression/Classification tasks
